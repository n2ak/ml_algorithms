{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Tensor,cross_entropy,Adam,SGD,Linear, Module, Sequential, ReLU,dataloader,Conv2D\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "train_X, train_y = sklearn.datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self, outc, impl):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential(\n",
    "            Conv2D(None, 64, 3, conv_impl=impl),\n",
    "            ReLU(),\n",
    "            lambda x: x.reshape(x.shape[0], -1),\n",
    "            Linear(None, outc,bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(net,optim,train_X,train_y,epochs):\n",
    "    if train_X.ndim == 2:\n",
    "        h=w=int(np.sqrt(train_X.shape[1]))\n",
    "        train_X = train_X.reshape(train_X.shape[0],1,h,w)\n",
    "    import time\n",
    "    start = time.monotonic()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        losses = []\n",
    "        accs = []\n",
    "        for X, y in dataloader(64*2, train_X, train_y):\n",
    "            # forward + backward + optimize\n",
    "            outputs = net.forward(X)\n",
    "            loss = cross_entropy(outputs, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            assert loss.item() >= 0, loss\n",
    "            optim.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accs.append((outputs.data.argmax(-1) == y.data).astype(float).mean())\n",
    "        print(\n",
    "            f'[Epoch {epoch + 1:3}] loss: {np.mean(losses):.3f} accuracy: {np.mean(accs)*100:3.2f}')\n",
    "    return time.monotonic() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 43.823 accuracy: 58.25\n",
      "[Epoch   2] loss: 9.948 accuracy: 84.06\n",
      "[Epoch   3] loss: 3.067 accuracy: 94.06\n",
      "[Epoch   4] loss: 1.274 accuracy: 97.40\n",
      "[Epoch   5] loss: 0.793 accuracy: 98.02\n",
      "[Epoch   6] loss: 0.561 accuracy: 98.91\n",
      "[Epoch   7] loss: 0.389 accuracy: 97.78\n",
      "[Epoch   8] loss: 1.785 accuracy: 94.76\n",
      "[Epoch   9] loss: 2.008 accuracy: 95.62\n",
      "[Epoch  10] loss: 0.626 accuracy: 97.86\n",
      "Finished Training in : 14.9060 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(np.unique(train_y).size, impl=\"slow\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 60.042 accuracy: 47.29\n",
      "[Epoch   2] loss: 12.752 accuracy: 84.45\n",
      "[Epoch   3] loss: 3.336 accuracy: 94.32\n",
      "[Epoch   4] loss: 1.958 accuracy: 95.59\n",
      "[Epoch   5] loss: 3.038 accuracy: 94.34\n",
      "[Epoch   6] loss: 1.974 accuracy: 95.47\n",
      "[Epoch   7] loss: 1.305 accuracy: 96.69\n",
      "[Epoch   8] loss: 1.226 accuracy: 96.77\n",
      "[Epoch   9] loss: 0.608 accuracy: 98.39\n",
      "[Epoch  10] loss: 0.351 accuracy: 99.01\n",
      "Finished Training in : 11.1720 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(np.unique(train_y).size, impl=\"fast_forward\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 53.737 accuracy: 47.24\n",
      "[Epoch   2] loss: 8.990 accuracy: 88.88\n",
      "[Epoch   3] loss: 3.778 accuracy: 93.02\n",
      "[Epoch   4] loss: 1.675 accuracy: 96.51\n",
      "[Epoch   5] loss: 0.988 accuracy: 97.66\n",
      "[Epoch   6] loss: 2.129 accuracy: 97.05\n",
      "[Epoch   7] loss: 1.704 accuracy: 95.33\n",
      "[Epoch   8] loss: 2.086 accuracy: 95.10\n",
      "[Epoch   9] loss: 0.918 accuracy: 96.64\n",
      "[Epoch  10] loss: 2.431 accuracy: 96.15\n",
      "Finished Training in : 2.8130 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(np.unique(train_y).size, impl=\"fast\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
