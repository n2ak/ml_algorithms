{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Tensor,cross_entropy,Adam,SGD,Linear, Module, Sequential, ReLU,dataloader,Conv2D\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "train_X, train_y = sklearn.datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self, outc, impl):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential(\n",
    "            Conv2D(None, 64, 3, conv_impl=impl),\n",
    "            ReLU(),\n",
    "            lambda x: x.reshape(x.shape[0], -1),\n",
    "            Linear(None, outc,bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(net,optim,train_X,train_y,epochs):\n",
    "    if train_X.ndim == 2:\n",
    "        h=w=int(np.sqrt(train_X.shape[1]))\n",
    "        train_X = train_X.reshape(train_X.shape[0],1,h,w)\n",
    "    import time\n",
    "    start = time.monotonic()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        losses = []\n",
    "        accs = []\n",
    "        for X, y in dataloader(64*2, train_X, train_y):\n",
    "            # forward + backward + optimize\n",
    "            outputs = net.forward(X)\n",
    "            loss = cross_entropy(outputs, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            assert loss.item() >= 0, loss\n",
    "            optim.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accs.append((outputs.data.argmax(-1) == y.data).astype(float).mean())\n",
    "        print(\n",
    "            f'[Epoch {epoch + 1:3}] loss: {np.mean(losses):.3f} accuracy: {np.mean(accs)*100:3.2f}')\n",
    "    return time.monotonic() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 58.610 accuracy: 45.54\n",
      "[Epoch   2] loss: 5.874 accuracy: 90.57\n",
      "[Epoch   3] loss: 2.602 accuracy: 95.10\n",
      "[Epoch   4] loss: 1.701 accuracy: 95.44\n",
      "[Epoch   5] loss: 2.207 accuracy: 94.22\n",
      "[Epoch   6] loss: 1.199 accuracy: 96.82\n",
      "[Epoch   7] loss: 0.510 accuracy: 98.49\n",
      "[Epoch   8] loss: 0.312 accuracy: 98.96\n",
      "[Epoch   9] loss: 0.226 accuracy: 99.22\n",
      "[Epoch  10] loss: 0.142 accuracy: 99.48\n",
      "Finished Training in : 14.7970 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(np.unique(train_y).size, impl=\"slow\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 50.579 accuracy: 48.61\n",
      "[Epoch   2] loss: 8.676 accuracy: 86.72\n",
      "[Epoch   3] loss: 3.505 accuracy: 92.89\n",
      "[Epoch   4] loss: 2.715 accuracy: 95.52\n",
      "[Epoch   5] loss: 1.295 accuracy: 97.03\n",
      "[Epoch   6] loss: 0.767 accuracy: 98.33\n",
      "[Epoch   7] loss: 0.454 accuracy: 98.59\n",
      "[Epoch   8] loss: 0.230 accuracy: 98.96\n",
      "[Epoch   9] loss: 0.148 accuracy: 99.17\n",
      "[Epoch  10] loss: 0.129 accuracy: 99.01\n",
      "Finished Training in : 10.7500 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(np.unique(train_y).size, impl=\"fast_forward\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 76.765 accuracy: 50.05\n",
      "[Epoch   2] loss: 18.241 accuracy: 79.24\n",
      "[Epoch   3] loss: 4.046 accuracy: 94.01\n",
      "[Epoch   4] loss: 2.149 accuracy: 96.51\n",
      "[Epoch   5] loss: 1.276 accuracy: 97.81\n",
      "[Epoch   6] loss: 0.806 accuracy: 98.28\n",
      "[Epoch   7] loss: 0.544 accuracy: 98.49\n",
      "[Epoch   8] loss: 0.408 accuracy: 99.11\n",
      "[Epoch   9] loss: 0.315 accuracy: 98.91\n",
      "[Epoch  10] loss: 0.262 accuracy: 99.22\n",
      "Finished Training in : 1.1720 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(np.unique(train_y).size, impl=\"fast\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
