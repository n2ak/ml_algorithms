{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Tensor,cross_entropy,Adam,SGD,Linear, Module, Sequential, ReLU,dataloader,Conv2D\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "train_X, train_y = sklearn.datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self, inc, outc, impl):\n",
    "        super().__init__()\n",
    "        self.seq = Sequential(\n",
    "            Conv2D(inc, 64, 3, conv_impl=impl),\n",
    "            ReLU(),\n",
    "            lambda x: x.reshape(x.shape[0], -1),\n",
    "            Linear(2304, outc,bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(net,optim,train_X,train_y,epochs):\n",
    "    if train_X.ndim == 2:\n",
    "        h=w=int(np.sqrt(train_X.shape[1]))\n",
    "        train_X = train_X.reshape(train_X.shape[0],1,h,w)\n",
    "    import time\n",
    "    start = time.monotonic()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        losses = []\n",
    "        accs = []\n",
    "        for X, y in dataloader(64*2, train_X, train_y):\n",
    "            # forward + backward + optimize\n",
    "            outputs = net.forward(X)\n",
    "            loss = cross_entropy(outputs, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            assert loss.item() >= 0, loss\n",
    "            optim.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accs.append((outputs.data.argmax(-1) == y.data).astype(float).mean())\n",
    "        print(\n",
    "            f'[Epoch {epoch + 1:3}] loss: {np.mean(losses):.3f} accuracy: {np.mean(accs)*100:3.2f}')\n",
    "    return time.monotonic() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 61.879 accuracy: 48.41\n",
      "[Epoch   2] loss: 10.776 accuracy: 83.67\n",
      "[Epoch   3] loss: 4.572 accuracy: 92.76\n",
      "[Epoch   4] loss: 1.929 accuracy: 96.46\n",
      "[Epoch   5] loss: 1.087 accuracy: 97.55\n",
      "[Epoch   6] loss: 0.729 accuracy: 98.12\n",
      "[Epoch   7] loss: 0.413 accuracy: 98.39\n",
      "[Epoch   8] loss: 0.266 accuracy: 98.75\n",
      "[Epoch   9] loss: 0.187 accuracy: 99.17\n",
      "[Epoch  10] loss: 0.159 accuracy: 99.32\n",
      "Finished Training in : 16.2030 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(1, np.unique(train_y).size, impl=\"slow\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 55.173 accuracy: 49.92\n",
      "[Epoch   2] loss: 6.965 accuracy: 89.74\n",
      "[Epoch   3] loss: 5.139 accuracy: 93.20\n",
      "[Epoch   4] loss: 2.280 accuracy: 95.57\n",
      "[Epoch   5] loss: 1.394 accuracy: 96.98\n",
      "[Epoch   6] loss: 0.857 accuracy: 98.18\n",
      "[Epoch   7] loss: 0.505 accuracy: 98.49\n",
      "[Epoch   8] loss: 0.304 accuracy: 98.96\n",
      "[Epoch   9] loss: 0.260 accuracy: 98.91\n",
      "[Epoch  10] loss: 0.168 accuracy: 99.48\n",
      "Finished Training in : 11.2810 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(1, np.unique(train_y).size, impl=\"fast_forward\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1] loss: 54.194 accuracy: 45.42\n",
      "[Epoch   2] loss: 10.706 accuracy: 86.77\n",
      "[Epoch   3] loss: 3.813 accuracy: 93.91\n",
      "[Epoch   4] loss: 2.438 accuracy: 95.02\n",
      "[Epoch   5] loss: 3.253 accuracy: 94.27\n",
      "[Epoch   6] loss: 1.434 accuracy: 97.08\n",
      "[Epoch   7] loss: 0.912 accuracy: 96.17\n",
      "[Epoch   8] loss: 1.450 accuracy: 95.99\n",
      "[Epoch   9] loss: 0.884 accuracy: 97.45\n",
      "[Epoch  10] loss: 0.383 accuracy: 98.49\n",
      "Finished Training in : 2.6090 s\n"
     ]
    }
   ],
   "source": [
    "net = Net(1, np.unique(train_y).size, impl=\"fast\")\n",
    "optimizer = Adam(net.trainable_params(), lr=0.001, amsgrad=True)\n",
    "time = train(net, optimizer, train_X, train_y, 10)\n",
    "print(f'Finished Training in : {time:.4f} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
